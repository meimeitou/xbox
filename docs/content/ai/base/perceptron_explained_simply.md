+++
title = 'æ„ŸçŸ¥æœº'
weight = 4
description = 'ä»ç”Ÿç‰©ç¥ç»å…ƒåˆ°äººå·¥æ™ºèƒ½çš„ç¬¬ä¸€æ­¥ï¼Œæ·±å…¥ç†è§£æ„ŸçŸ¥æœºçš„æ ¸å¿ƒæ€æƒ³ã€å®ç°åŸç†å’Œå®é™…åº”ç”¨ã€‚'
tags = ['æœºå™¨å­¦ä¹ ', 'æ„ŸçŸ¥æœº', 'äººå·¥æ™ºèƒ½', 'ç¥ç»ç½‘ç»œ']
+++

ä»ç”Ÿç‰©ç¥ç»å…ƒåˆ°äººå·¥æ™ºèƒ½çš„ç¬¬ä¸€æ­¥

- [ä»€ä¹ˆæ˜¯æ„ŸçŸ¥æœºï¼Ÿç”¨æœ€ç®€å•çš„è¯è¯´](#ä»€ä¹ˆæ˜¯æ„ŸçŸ¥æœºç”¨æœ€ç®€å•çš„è¯è¯´)
- [ç”Ÿæ´»ä¸­çš„æ„ŸçŸ¥æœºä¾‹å­](#ç”Ÿæ´»ä¸­çš„æ„ŸçŸ¥æœºä¾‹å­)
  - [ä¾‹å­1ï¼šè¦ä¸è¦ä¹°è¿™ä»¶è¡£æœï¼Ÿ](#ä¾‹å­1è¦ä¸è¦ä¹°è¿™ä»¶è¡£æœ)
  - [ä¾‹å­2ï¼šè¦ä¸è¦å‡ºé—¨ï¼Ÿ](#ä¾‹å­2è¦ä¸è¦å‡ºé—¨)
- [æ„ŸçŸ¥æœºçš„ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†](#æ„ŸçŸ¥æœºçš„ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†)
  - [1. è¾“å…¥ï¼ˆInputï¼‰- ä½ è€ƒè™‘çš„å› ç´ ](#1-è¾“å…¥input--ä½ è€ƒè™‘çš„å› ç´ )
  - [2. æƒé‡ï¼ˆWeightsï¼‰- æ¯ä¸ªå› ç´ çš„é‡è¦ç¨‹åº¦](#2-æƒé‡weights--æ¯ä¸ªå› ç´ çš„é‡è¦ç¨‹åº¦)
  - [3. æ¿€æ´»å‡½æ•°ï¼ˆActivationï¼‰- æœ€ç»ˆå†³å®šçš„è§„åˆ™](#3-æ¿€æ´»å‡½æ•°activation--æœ€ç»ˆå†³å®šçš„è§„åˆ™)
- [å®Œæ•´çš„æ„ŸçŸ¥æœºå®ç°](#å®Œæ•´çš„æ„ŸçŸ¥æœºå®ç°)
- [æ„ŸçŸ¥æœºçš„å±€é™æ€§ï¼šä¸èƒ½è§£å†³"å¼‚æˆ–"é—®é¢˜](#æ„ŸçŸ¥æœºçš„å±€é™æ€§ä¸èƒ½è§£å†³å¼‚æˆ–é—®é¢˜)
- [æ„ŸçŸ¥æœºçš„å­¦ä¹ è¿‡ç¨‹å¯è§†åŒ–](#æ„ŸçŸ¥æœºçš„å­¦ä¹ è¿‡ç¨‹å¯è§†åŒ–)
- [ç°å®ä¸–ç•Œçš„æ„ŸçŸ¥æœºåº”ç”¨](#ç°å®ä¸–ç•Œçš„æ„ŸçŸ¥æœºåº”ç”¨)
  - [åƒåœ¾é‚®ä»¶æ£€æµ‹å™¨](#åƒåœ¾é‚®ä»¶æ£€æµ‹å™¨)
- [æ„ŸçŸ¥æœº vs äººè„‘ç¥ç»å…ƒ](#æ„ŸçŸ¥æœº-vs-äººè„‘ç¥ç»å…ƒ)
- [æ„ŸçŸ¥æœºçš„å†å²æ•…äº‹](#æ„ŸçŸ¥æœºçš„å†å²æ•…äº‹)
- [ä»æ„ŸçŸ¥æœºåˆ°ç°ä»£AI](#ä»æ„ŸçŸ¥æœºåˆ°ç°ä»£ai)
- [åŠ¨æ‰‹å®è·µï¼šè®©æ„ŸçŸ¥æœºè¯†åˆ«æ•°å­—](#åŠ¨æ‰‹å®è·µè®©æ„ŸçŸ¥æœºè¯†åˆ«æ•°å­—)
- [æ€»ç»“ï¼šæ„ŸçŸ¥æœºçš„æ ¸å¿ƒæ€æƒ³](#æ€»ç»“æ„ŸçŸ¥æœºçš„æ ¸å¿ƒæ€æƒ³)
- [ç»“è¯­](#ç»“è¯­)

## ä»€ä¹ˆæ˜¯æ„ŸçŸ¥æœºï¼Ÿç”¨æœ€ç®€å•çš„è¯è¯´

æƒ³è±¡ä¸€ä¸‹ä½ çš„å¤§è„‘æ˜¯å¦‚ä½•åšå†³å®šçš„ã€‚æ¯”å¦‚æ—©ä¸Šèµ·åºŠæ—¶ï¼Œä½ ä¼šè€ƒè™‘ï¼š

- ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿâ˜€ï¸ğŸŒ§ï¸
- æˆ‘æœ‰é‡è¦çš„äº‹æƒ…å—ï¼ŸğŸ“…
- æ˜¨æ™šç¡å¾—å¥½å—ï¼ŸğŸ˜´

ä½ çš„å¤§è„‘ä¼š"æƒè¡¡"è¿™äº›å› ç´ ï¼Œç„¶åå†³å®šï¼šèµ·åºŠè¿˜æ˜¯ç»§ç»­ç¡ï¼Ÿ

**æ„ŸçŸ¥æœºå°±æ˜¯æ¨¡ä»¿è¿™ä¸ªè¿‡ç¨‹çš„æœ€ç®€å•çš„äººå·¥ç¥ç»å…ƒ**ï¼

## ç”Ÿæ´»ä¸­çš„æ„ŸçŸ¥æœºä¾‹å­

### ä¾‹å­1ï¼šè¦ä¸è¦ä¹°è¿™ä»¶è¡£æœï¼Ÿ

```python
# ä½ çš„å¤§è„‘åœ¨åšè¿™æ ·çš„è®¡ç®—ï¼š
ä»·æ ¼ = -50      # å¤ªè´µäº†ï¼Œå‡åˆ†ï¼
æ¬¾å¼ = +30      # å¾ˆå–œæ¬¢ï¼ŒåŠ åˆ†ï¼
è´¨é‡ = +40      # è´¨é‡å¾ˆå¥½ï¼ŒåŠ åˆ†ï¼
éœ€è¦ç¨‹åº¦ = +20  # ç¡®å®éœ€è¦ï¼ŒåŠ åˆ†ï¼

æ€»åˆ† = (-50) + 30 + 40 + 20 = 40

# å¦‚æœæ€»åˆ† > 0ï¼Œå°±ä¹°ï¼
# å¦‚æœæ€»åˆ† â‰¤ 0ï¼Œå°±ä¸ä¹°ï¼
```

è¿™å°±æ˜¯æ„ŸçŸ¥æœºçš„æ ¸å¿ƒæ€æƒ³ï¼

### ä¾‹å­2ï¼šè¦ä¸è¦å‡ºé—¨ï¼Ÿ

è®©æˆ‘ä»¬ç”¨ä»£ç æ¥æ¨¡æ‹Ÿï¼š

```python
def should_go_out(weather, mood, energy, plans):
    """
    æ„ŸçŸ¥æœºå†³ç­–ï¼šè¦ä¸è¦å‡ºé—¨ï¼Ÿ
    """
    # æ¯ä¸ªå› ç´ çš„æƒé‡ï¼ˆé‡è¦ç¨‹åº¦ï¼‰
    weather_weight = 0.4    # å¤©æ°”å¾ˆé‡è¦
    mood_weight = 0.3       # å¿ƒæƒ…æ¯”è¾ƒé‡è¦  
    energy_weight = 0.2     # ç²¾åŠ›ä¸€èˆ¬é‡è¦
    plans_weight = 0.1      # è®¡åˆ’ä¸å¤ªé‡è¦
    
    # åç½®é¡¹ï¼ˆä½ æœ¬èº«å°±å–œæ¬¢å®…åœ¨å®¶ï¼‰
    bias = -0.2
    
    # åŠ æƒæ±‚å’Œ
    total_score = (weather * weather_weight + 
                   mood * mood_weight + 
                   energy * energy_weight + 
                   plans * plans_weight + 
                   bias)
    
    # æ¿€æ´»å‡½æ•°ï¼šåšæœ€ç»ˆå†³å®š
    if total_score > 0:
        return "å‡ºé—¨ï¼"
    else:
        return "å®…åœ¨å®¶"

# æµ‹è¯•ä¸€ä¸‹
weather = 0.8   # å¤©æ°”å¾ˆå¥½ (0-1ä¹‹é—´)
mood = 0.6      # å¿ƒæƒ…ä¸é”™
energy = 0.4    # æœ‰ç‚¹ç´¯
plans = 0.9     # æœ‰é‡è¦è®¡åˆ’

decision = should_go_out(weather, mood, energy, plans)
print(f"å†³å®šï¼š{decision}")
```

## æ„ŸçŸ¥æœºçš„ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†

### 1. è¾“å…¥ï¼ˆInputï¼‰- ä½ è€ƒè™‘çš„å› ç´ 

```python
import numpy as np
import matplotlib.pyplot as plt

# æ¯”å¦‚åˆ¤æ–­ä¸€ä¸ªå­¦ç”Ÿèƒ½å¦é€šè¿‡è€ƒè¯•
inputs = {
    'ä¸Šè¯¾å‡ºå‹¤ç‡': 0.8,    # x1
    'ä½œä¸šå®Œæˆåº¦': 0.6,    # x2  
    'å¤ä¹ æ—¶é—´': 0.7,      # x3
    'ä¹‹å‰æˆç»©': 0.5       # x4
}

print("è€ƒè™‘çš„å› ç´ ï¼š")
for factor, value in inputs.items():
    print(f"  {factor}: {value}")
```

### 2. æƒé‡ï¼ˆWeightsï¼‰- æ¯ä¸ªå› ç´ çš„é‡è¦ç¨‹åº¦

```python
# æƒé‡è¡¨ç¤ºæ¯ä¸ªå› ç´ æœ‰å¤šé‡è¦
weights = {
    'ä¸Šè¯¾å‡ºå‹¤ç‡': 0.3,    # w1 - æ¯”è¾ƒé‡è¦
    'ä½œä¸šå®Œæˆåº¦': 0.4,    # w2 - å¾ˆé‡è¦ï¼
    'å¤ä¹ æ—¶é—´': 0.5,      # w3 - æœ€é‡è¦ï¼
    'ä¹‹å‰æˆç»©': 0.2       # w4 - å‚è€ƒä½œç”¨
}

print("\næ¯ä¸ªå› ç´ çš„é‡è¦ç¨‹åº¦ï¼š")
for factor, weight in weights.items():
    importance = "â­" * int(weight * 10)
    print(f"  {factor}: {importance}")
```

### 3. æ¿€æ´»å‡½æ•°ï¼ˆActivationï¼‰- æœ€ç»ˆå†³å®šçš„è§„åˆ™

```python
def step_function(x):
    """
    é˜¶è·ƒå‡½æ•°ï¼šæœ€ç®€å•çš„æ¿€æ´»å‡½æ•°
    å°±åƒå¼€å…³ä¸€æ ·ï¼Œè¦ä¹ˆå¼€ï¼Œè¦ä¹ˆå…³
    """
    if x >= 0:
        return 1  # é€šè¿‡è€ƒè¯•
    else:
        return 0  # ä¸é€šè¿‡è€ƒè¯•

def plot_step_function():
    """å¯è§†åŒ–é˜¶è·ƒå‡½æ•°"""
    x = np.linspace(-2, 2, 100)
    y = [step_function(xi) for xi in x]
    
    plt.figure(figsize=(8, 5))
    plt.plot(x, y, 'b-', linewidth=3, label='é˜¶è·ƒå‡½æ•°')
    plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='å†³ç­–è¾¹ç•Œ')
    plt.axvline(x=0, color='r', linestyle='--', alpha=0.7)
    
    plt.xlabel('è¾“å…¥æ€»åˆ†')
    plt.ylabel('è¾“å‡ºç»“æœ')
    plt.title('æ„ŸçŸ¥æœºçš„æ¿€æ´»å‡½æ•° - å°±åƒå¼€å…³')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ æ³¨é‡Š
    plt.annotate('ä¸é€šè¿‡', xy=(-1, 0), xytext=(-1.5, 0.2),
                arrowprops=dict(arrowstyle='->', color='red'),
                fontsize=12, color='red')
    plt.annotate('é€šè¿‡', xy=(1, 1), xytext=(1.5, 0.8),
                arrowprops=dict(arrowstyle='->', color='green'),
                fontsize=12, color='green')
    
    plt.show()

plot_step_function()
```

## å®Œæ•´çš„æ„ŸçŸ¥æœºå®ç°

è®©æˆ‘ä»¬æ‰‹å†™ä¸€ä¸ªç®€å•çš„æ„ŸçŸ¥æœºï¼š

```python
class SimplePerceptron:
    """ç®€å•æ˜“æ‡‚çš„æ„ŸçŸ¥æœºå®ç°"""
    
    def __init__(self, input_size, learning_rate=0.1):
        """
        åˆå§‹åŒ–æ„ŸçŸ¥æœº
        input_size: è¾“å…¥ç‰¹å¾çš„æ•°é‡
        learning_rate: å­¦ä¹ é€Ÿåº¦
        """
        # éšæœºåˆå§‹åŒ–æƒé‡ï¼ˆå°±åƒå©´å„¿å¤§è„‘çš„éšæœºè¿æ¥ï¼‰
        self.weights = np.random.random(input_size) * 0.1
        self.bias = 0.0  # åç½®é¡¹
        self.learning_rate = learning_rate
        
        print(f"ğŸ§  æ„ŸçŸ¥æœºè¯ç”Ÿäº†ï¼æœ‰ {input_size} ä¸ªè¾“å…¥")
        print(f"åˆå§‹æƒé‡: {self.weights}")
    
    def predict(self, inputs):
        """
        è¿›è¡Œé¢„æµ‹ï¼ˆåšå†³å®šï¼‰
        """
        # ç¬¬ä¸€æ­¥ï¼šè®¡ç®—åŠ æƒå’Œ
        weighted_sum = np.dot(inputs, self.weights) + self.bias
        
        # ç¬¬äºŒæ­¥ï¼šé€šè¿‡æ¿€æ´»å‡½æ•°å¾—å‡ºç»“æœ
        if weighted_sum >= 0:
            return 1
        else:
            return 0
    
    def train_step(self, inputs, target):
        """
        è®­ç»ƒä¸€æ­¥ï¼ˆä»é”™è¯¯ä¸­å­¦ä¹ ï¼‰
        """
        # å…ˆé¢„æµ‹
        prediction = self.predict(inputs)
        
        # è®¡ç®—é”™è¯¯
        error = target - prediction
        
        # å¦‚æœé¢„æµ‹é”™äº†ï¼Œå°±è°ƒæ•´æƒé‡
        if error != 0:
            # è°ƒæ•´æƒé‡ï¼ˆè¿™å°±æ˜¯å­¦ä¹ ï¼ï¼‰
            self.weights += self.learning_rate * error * inputs
            self.bias += self.learning_rate * error
            
            print(f"ğŸ˜… é¢„æµ‹é”™äº†ï¼è°ƒæ•´æƒé‡...")
            print(f"æ–°æƒé‡: {self.weights}")
            return True  # å‘ç”Ÿäº†å­¦ä¹ 
        else:
            print("âœ… é¢„æµ‹æ­£ç¡®ï¼")
            return False  # æ²¡æœ‰å­¦ä¹ 

# åˆ›å»ºä¸€ä¸ªæ„ŸçŸ¥æœºæ¥å­¦ä¹ é€»è¾‘"ä¸"è¿ç®—
print("=== æ•™æ„ŸçŸ¥æœºå­¦ä¼šé€»è¾‘'ä¸'è¿ç®— ===")
perceptron = SimplePerceptron(input_size=2)

# è®­ç»ƒæ•°æ®ï¼šé€»è¾‘ä¸çš„çœŸå€¼è¡¨
training_data = [
    ([0, 0], 0),  # 0 AND 0 = 0
    ([0, 1], 0),  # 0 AND 1 = 0  
    ([1, 0], 0),  # 1 AND 0 = 0
    ([1, 1], 1),  # 1 AND 1 = 1
]

print("\nè®­ç»ƒæ•°æ®ï¼ˆé€»è¾‘ä¸è¿ç®—ï¼‰ï¼š")
for inputs, output in training_data:
    print(f"  {inputs[0]} AND {inputs[1]} = {output}")

# å¼€å§‹è®­ç»ƒ
print("\nğŸ“ å¼€å§‹è®­ç»ƒ...")
max_epochs = 10
for epoch in range(max_epochs):
    print(f"\n--- ç¬¬ {epoch + 1} è½®è®­ç»ƒ ---")
    learned_something = False
    
    for inputs, target in training_data:
        print(f"\nè¾“å…¥: {inputs}, æœŸæœ›è¾“å‡º: {target}")
        if perceptron.train_step(inputs, target):
            learned_something = True
    
    # å¦‚æœè¿™ä¸€è½®æ²¡æœ‰è°ƒæ•´æƒé‡ï¼Œè¯´æ˜å­¦ä¼šäº†
    if not learned_something:
        print(f"\nğŸ‰ å¤ªæ£’äº†ï¼æ„ŸçŸ¥æœºåœ¨ç¬¬ {epoch + 1} è½®å°±å­¦ä¼šäº†ï¼")
        break

# æµ‹è¯•å­¦ä¹ ç»“æœ
print("\n=== æµ‹è¯•å­¦ä¹ ç»“æœ ===")
for inputs, expected in training_data:
    prediction = perceptron.predict(inputs)
    result = "âœ…" if prediction == expected else "âŒ"
    print(f"{inputs[0]} AND {inputs[1]} = {prediction} {result}")
```

## æ„ŸçŸ¥æœºçš„å±€é™æ€§ï¼šä¸èƒ½è§£å†³"å¼‚æˆ–"é—®é¢˜

```python
def demonstrate_xor_limitation():
    """æ¼”ç¤ºæ„ŸçŸ¥æœºä¸èƒ½è§£å†³XORé—®é¢˜"""
    
    print("=== æŒ‘æˆ˜ï¼šè®©æ„ŸçŸ¥æœºå­¦ä¹ 'å¼‚æˆ–'è¿ç®— ===")
    
    # XORï¼ˆå¼‚æˆ–ï¼‰çš„çœŸå€¼è¡¨
    xor_data = [
        ([0, 0], 0),  # 0 XOR 0 = 0
        ([0, 1], 1),  # 0 XOR 1 = 1
        ([1, 0], 1),  # 1 XOR 0 = 1  
        ([1, 1], 0),  # 1 XOR 1 = 0
    ]
    
    print("XORè¿ç®—çœŸå€¼è¡¨ï¼š")
    for inputs, output in xor_data:
        print(f"  {inputs[0]} XOR {inputs[1]} = {output}")
    
    # å¯è§†åŒ–XORé—®é¢˜
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # ANDé—®é¢˜ï¼ˆçº¿æ€§å¯åˆ†ï¼‰
    ax1.scatter([0, 0, 1], [0, 1, 0], c='red', s=100, label='è¾“å‡º=0')
    ax1.scatter([1], [1], c='blue', s=100, label='è¾“å‡º=1')
    ax1.plot([0.5, 0.5], [0, 1], 'g--', linewidth=2, label='å†³ç­–è¾¹ç•Œ')
    ax1.set_title('ANDè¿ç®— - å¯ä»¥ç”¨ä¸€æ¡ç›´çº¿åˆ†å¼€')
    ax1.set_xlabel('è¾“å…¥1')
    ax1.set_ylabel('è¾“å…¥2')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # XORé—®é¢˜ï¼ˆçº¿æ€§ä¸å¯åˆ†ï¼‰
    ax2.scatter([0, 1], [0, 1], c='red', s=100, label='è¾“å‡º=0')
    ax2.scatter([0, 1], [1, 0], c='blue', s=100, label='è¾“å‡º=1')
    ax2.set_title('XORè¿ç®— - æ— æ³•ç”¨ä¸€æ¡ç›´çº¿åˆ†å¼€ï¼')
    ax2.set_xlabel('è¾“å…¥1')
    ax2.set_ylabel('è¾“å…¥2')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # ç”»å‡ æ¡è¯•å›¾åˆ†ç¦»çš„ç›´çº¿
    x = np.linspace(-0.2, 1.2, 100)
    ax2.plot(x, 0.5*np.ones_like(x), 'r--', alpha=0.5, label='å°è¯•1')
    ax2.plot(0.5*np.ones_like(x), x, 'g--', alpha=0.5, label='å°è¯•2')
    ax2.plot(x, x, 'm--', alpha=0.5, label='å°è¯•3')
    
    plt.tight_layout()
    plt.show()
    
    print("\nğŸ’¡ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å¤šå±‚ç¥ç»ç½‘ç»œï¼")

demonstrate_xor_limitation()
```

## æ„ŸçŸ¥æœºçš„å­¦ä¹ è¿‡ç¨‹å¯è§†åŒ–

```python
def visualize_learning_process():
    """å¯è§†åŒ–æ„ŸçŸ¥æœºçš„å­¦ä¹ è¿‡ç¨‹"""
    
    # ç”Ÿæˆç®€å•çš„äºŒåˆ†ç±»æ•°æ®
    np.random.seed(42)
    
    # ç±»åˆ«1ï¼šè€ƒè¯•é€šè¿‡çš„å­¦ç”Ÿ
    class1 = np.random.normal([0.7, 0.8], 0.1, (20, 2))
    
    # ç±»åˆ«2ï¼šè€ƒè¯•ä¸é€šè¿‡çš„å­¦ç”Ÿ  
    class2 = np.random.normal([0.3, 0.2], 0.1, (20, 2))
    
    # åˆå¹¶æ•°æ®
    X = np.vstack([class1, class2])
    y = np.hstack([np.ones(20), np.zeros(20)])
    
    # åˆ›å»ºæ„ŸçŸ¥æœº
    perceptron = SimplePerceptron(input_size=2, learning_rate=0.1)
    
    # è®°å½•å­¦ä¹ è¿‡ç¨‹
    history = []
    
    plt.figure(figsize=(15, 5))
    
    for epoch in range(3):
        plt.subplot(1, 3, epoch + 1)
        
        # ç»˜åˆ¶æ•°æ®ç‚¹
        plt.scatter(class1[:, 0], class1[:, 1], c='green', s=50, 
                   alpha=0.7, label='é€šè¿‡è€ƒè¯• âœ…')
        plt.scatter(class2[:, 0], class2[:, 1], c='red', s=50, 
                   alpha=0.7, label='ä¸é€šè¿‡è€ƒè¯• âŒ')
        
        # ç»˜åˆ¶å½“å‰çš„å†³ç­–è¾¹ç•Œ
        if abs(perceptron.weights[1]) > 1e-6:  # é¿å…é™¤é›¶
            x_line = np.linspace(0, 1, 100)
            # w1*x1 + w2*x2 + bias = 0
            # x2 = -(w1*x1 + bias) / w2
            y_line = -(perceptron.weights[0] * x_line + perceptron.bias) / perceptron.weights[1]
            
            # åªæ˜¾ç¤ºåœ¨å›¾å½¢èŒƒå›´å†…çš„éƒ¨åˆ†
            mask = (y_line >= 0) & (y_line <= 1)
            plt.plot(x_line[mask], y_line[mask], 'b-', linewidth=2, 
                    label=f'å†³ç­–è¾¹ç•Œ (ç¬¬{epoch+1}è½®)')
        
        plt.xlim(0, 1)
        plt.ylim(0, 1)
        plt.xlabel('å­¦ä¹ åŠªåŠ›ç¨‹åº¦')
        plt.ylabel('åŸºç¡€èƒ½åŠ›')
        plt.title(f'ç¬¬ {epoch + 1} è½®è®­ç»ƒå')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # è®­ç»ƒä¸€è½®
        for i in range(len(X)):
            perceptron.train_step(X[i], y[i])
    
    plt.tight_layout()
    plt.show()
    
    print("ğŸ“ˆ å¯ä»¥çœ‹åˆ°å†³ç­–è¾¹ç•Œåœ¨ä¸æ–­è°ƒæ•´ï¼Œç›´åˆ°æ­£ç¡®åˆ†ç±»æ‰€æœ‰æ•°æ®ç‚¹ï¼")

visualize_learning_process()
```

## ç°å®ä¸–ç•Œçš„æ„ŸçŸ¥æœºåº”ç”¨

### åƒåœ¾é‚®ä»¶æ£€æµ‹å™¨

```python
class SpamDetector:
    """åƒåœ¾é‚®ä»¶æ£€æµ‹å™¨ - æ„ŸçŸ¥æœºçš„å®é™…åº”ç”¨"""
    
    def __init__(self):
        self.perceptron = SimplePerceptron(input_size=5)
        self.feature_names = [
            'åŒ…å«"å…è´¹"', 
            'åŒ…å«"èµšé’±"', 
            'å…¨å¤§å†™å­—æ¯', 
            'å¤šä¸ªæ„Ÿå¹å·',
            'å¯ç–‘é“¾æ¥'
        ]
    
    def extract_features(self, email_text):
        """ä»é‚®ä»¶ä¸­æå–ç‰¹å¾"""
        features = []
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«"å…è´¹"
        features.append(1 if 'å…è´¹' in email_text else 0)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«"èµšé’±"
        features.append(1 if 'èµšé’±' in email_text else 0)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¾ˆå¤šå¤§å†™å­—æ¯
        uppercase_ratio = sum(1 for c in email_text if c.isupper()) / len(email_text)
        features.append(1 if uppercase_ratio > 0.5 else 0)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªæ„Ÿå¹å·
        features.append(1 if email_text.count('!') > 2 else 0)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç–‘é“¾æ¥
        features.append(1 if 'http://' in email_text and 'å¯ç–‘' in email_text else 0)
        
        return np.array(features)
    
    def train(self, emails, labels):
        """è®­ç»ƒåƒåœ¾é‚®ä»¶æ£€æµ‹å™¨"""
        print("ğŸ“ è®­ç»ƒåƒåœ¾é‚®ä»¶æ£€æµ‹å™¨...")
        
        for epoch in range(5):
            print(f"\nç¬¬ {epoch + 1} è½®è®­ç»ƒï¼š")
            for email, label in zip(emails, labels):
                features = self.extract_features(email)
                self.perceptron.train_step(features, label)
    
    def predict(self, email_text):
        """é¢„æµ‹é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶"""
        features = self.extract_features(email_text)
        result = self.perceptron.predict(features)
        
        print(f"\né‚®ä»¶å†…å®¹: '{email_text}'")
        print("ç‰¹å¾åˆ†æ:")
        for name, value in zip(self.feature_names, features):
            status = "âœ“" if value else "âœ—"
            print(f"  {name}: {status}")
        
        if result == 1:
            print("ğŸš¨ åˆ¤å®š: åƒåœ¾é‚®ä»¶")
        else:
            print("âœ… åˆ¤å®š: æ­£å¸¸é‚®ä»¶")
        
        return result

# è®­ç»ƒæ•°æ®
training_emails = [
    "å…è´¹èµšé’±æœºä¼šï¼ï¼ï¼ç‚¹å‡»è¿™é‡Œ", # åƒåœ¾é‚®ä»¶
    "æ‚¨å¥½ï¼Œè¿™æ˜¯å·¥ä½œé‚®ä»¶", # æ­£å¸¸é‚®ä»¶  
    "æ­å–œæ‚¨ä¸­å¥–äº†ï¼å…è´¹é¢†å–ï¼ï¼ï¼", # åƒåœ¾é‚®ä»¶
    "æ˜å¤©å¼€ä¼šï¼Œè¯·å‡†å¤‡èµ„æ–™", # æ­£å¸¸é‚®ä»¶
    "èµšé’±ç§˜ç±ï¼ï¼ï¼ç«‹å³è¡ŒåŠ¨", # åƒåœ¾é‚®ä»¶
]

training_labels = [1, 0, 1, 0, 1]  # 1=åƒåœ¾é‚®ä»¶, 0=æ­£å¸¸é‚®ä»¶

# åˆ›å»ºå¹¶è®­ç»ƒæ£€æµ‹å™¨
detector = SpamDetector()
detector.train(training_emails, training_labels)

# æµ‹è¯•
test_emails = [
    "å…è´¹åˆé¤æ´»åŠ¨é€šçŸ¥",
    "æ‚¨å¥½ï¼Œè¯·æŸ¥æ”¶é™„ä»¶",  
    "èµšé’±æœºä¼šï¼ï¼ï¼",
]

print("\n=== æµ‹è¯•åƒåœ¾é‚®ä»¶æ£€æµ‹å™¨ ===")
for email in test_emails:
    detector.predict(email)
    print("-" * 50)
```

## æ„ŸçŸ¥æœº vs äººè„‘ç¥ç»å…ƒ

```python
def compare_biological_artificial():
    """æ¯”è¾ƒç”Ÿç‰©ç¥ç»å…ƒå’Œäººå·¥æ„ŸçŸ¥æœº"""
    
    comparison = {
        "ç‰¹å¾": ["è¾“å…¥", "å¤„ç†", "è¾“å‡º", "å­¦ä¹ ", "é€Ÿåº¦"],
        "ç”Ÿç‰©ç¥ç»å…ƒ": [
            "é€šè¿‡æ ‘çªæ¥æ”¶ä¿¡å·", 
            "åœ¨ç»†èƒä½“å†…æ•´åˆä¿¡å·",
            "é€šè¿‡è½´çªå‘é€åŠ¨ä½œç”µä½",
            "é€šè¿‡çªè§¦å¼ºåº¦å˜åŒ–å­¦ä¹ ",
            "æ¯«ç§’çº§å“åº”"
        ],
        "äººå·¥æ„ŸçŸ¥æœº": [
            "æ•°å€¼è¾“å…¥å‘é‡",
            "åŠ æƒæ±‚å’Œ + æ¿€æ´»å‡½æ•°", 
            "0æˆ–1çš„æ•°å­—è¾“å‡º",
            "é€šè¿‡è°ƒæ•´æƒé‡å­¦ä¹ ",
            "å¾®ç§’çº§è®¡ç®—"
        ]
    }
    
    print("ğŸ§  ç”Ÿç‰©ç¥ç»å…ƒ vs ğŸ¤– äººå·¥æ„ŸçŸ¥æœº")
    print("=" * 60)
    
    for i, feature in enumerate(comparison["ç‰¹å¾"]):
        print(f"\n{feature}:")
        print(f"  ğŸ§  ç”Ÿç‰©: {comparison['ç”Ÿç‰©ç¥ç»å…ƒ'][i]}")
        print(f"  ğŸ¤– äººå·¥: {comparison['äººå·¥æ„ŸçŸ¥æœº'][i]}")
    
    print("\nğŸ’¡ ç›¸åŒç‚¹:")
    print("  - éƒ½æ¥æ”¶å¤šä¸ªè¾“å…¥")
    print("  - éƒ½è¿›è¡ŒæŸç§'è®¡ç®—'")  
    print("  - éƒ½äº§ç”Ÿè¾“å‡ºä¿¡å·")
    print("  - éƒ½å¯ä»¥é€šè¿‡ç»éªŒå­¦ä¹ ")
    
    print("\nğŸ”„ ä¸åŒç‚¹:")
    print("  - ç”Ÿç‰©ç¥ç»å…ƒæ›´å¤æ‚ï¼Œæœ‰æ—¶é—´åŠ¨æ€")
    print("  - äººå·¥æ„ŸçŸ¥æœºæ›´ç®€å•ï¼Œä¾¿äºæ•°å­¦åˆ†æ")
    print("  - ç”Ÿç‰©ç¥ç»å…ƒå¤„ç†æ¨¡æ‹Ÿä¿¡å·")
    print("  - äººå·¥æ„ŸçŸ¥æœºå¤„ç†æ•°å­—ä¿¡å·")

compare_biological_artificial()
```

## æ„ŸçŸ¥æœºçš„å†å²æ•…äº‹

```python
def perceptron_history():
    """æ„ŸçŸ¥æœºçš„æœ‰è¶£å†å²"""
    
    timeline = {
        "1943å¹´": "McCullochå’ŒPittsæå‡ºç¬¬ä¸€ä¸ªæ•°å­¦ç¥ç»å…ƒæ¨¡å‹",
        "1957å¹´": "Rosenblattå‘æ˜æ„ŸçŸ¥æœºï¼Œå¼•èµ·å·¨å¤§è½°åŠ¨",
        "1958å¹´": "ç¬¬ä¸€å°æ„ŸçŸ¥æœºç¡¬ä»¶Mark Iè¯ç”Ÿ",
        "1969å¹´": "Minskyå’ŒPapertæŒ‡å‡ºæ„ŸçŸ¥æœºçš„å±€é™æ€§",
        "1970s-1980s": "AIè¿›å…¥'å¯‚é™æœŸ'",  
        "1986å¹´": "åå‘ä¼ æ’­ç®—æ³•é‡ç‡ƒç¥ç»ç½‘ç»œå¸Œæœ›",
        "2010s": "æ·±åº¦å­¦ä¹ çˆ†å‘ï¼Œæ„ŸçŸ¥æœºæˆä¸ºåŸºç¡€"
    }
    
    print("ğŸ“œ æ„ŸçŸ¥æœºçš„ä¼ å¥‡å†å²")
    print("=" * 50)
    
    for year, event in timeline.items():
        print(f"{year}: {event}")
    
    print("\nğŸ¯ æœ‰è¶£çš„äº‹å®:")
    print("  - Rosenblattæ›¾é¢„è¨€æ„ŸçŸ¥æœºå°†èƒ½'è¡Œèµ°ã€è¯´è¯ã€çœ‹è§ã€å†™å­—'")
    print("  - ç¬¬ä¸€å°æ„ŸçŸ¥æœºé‡è¾¾5å¨ï¼")
    print("  - åª’ä½“ç§°å…¶ä¸º'ä¼šæ€è€ƒçš„æœºå™¨'")
    print("  - XORé—®é¢˜çš„å‘ç°å‡ ä¹æ€æ­»äº†æ•´ä¸ªé¢†åŸŸ")
    print("  - ä»Šå¤©æœ€å¤æ‚çš„AIä»ç„¶åŸºäºæ„ŸçŸ¥æœºçš„åŸç†")

perceptron_history()
```

## ä»æ„ŸçŸ¥æœºåˆ°ç°ä»£AI

```python
def evolution_to_modern_ai():
    """ä»æ„ŸçŸ¥æœºåˆ°ç°ä»£AIçš„æ¼”åŒ–"""
    
    print("ğŸš€ ä»æ„ŸçŸ¥æœºåˆ°ç°ä»£AIçš„æ¼”åŒ–ä¹‹è·¯")
    print("=" * 50)
    
    stages = [
        {
            "é˜¶æ®µ": "å•ä¸ªæ„ŸçŸ¥æœº",
            "èƒ½åŠ›": "çº¿æ€§åˆ†ç±»",
            "å±€é™": "æ— æ³•å¤„ç†XORç­‰é—®é¢˜",
            "ä¾‹å­": "ç®€å•çš„æ˜¯/å¦åˆ¤æ–­"
        },
        {
            "é˜¶æ®µ": "å¤šå±‚æ„ŸçŸ¥æœº", 
            "èƒ½åŠ›": "éçº¿æ€§åˆ†ç±»",
            "å±€é™": "è®­ç»ƒå›°éš¾",
            "ä¾‹å­": "å¤æ‚æ¨¡å¼è¯†åˆ«"
        },
        {
            "é˜¶æ®µ": "åå‘ä¼ æ’­ç¥ç»ç½‘ç»œ",
            "èƒ½åŠ›": "å¯è®­ç»ƒçš„å¤šå±‚ç½‘ç»œ", 
            "å±€é™": "æ¢¯åº¦æ¶ˆå¤±é—®é¢˜",
            "ä¾‹å­": "æ‰‹å†™æ•°å­—è¯†åˆ«"
        },
        {
            "é˜¶æ®µ": "æ·±åº¦å­¦ä¹ ",
            "èƒ½åŠ›": "å±‚æ¬¡ç‰¹å¾å­¦ä¹ ",
            "å±€é™": "éœ€è¦å¤§é‡æ•°æ®",
            "ä¾‹å­": "å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«"
        },
        {
            "é˜¶æ®µ": "Transformer/GPT",
            "èƒ½åŠ›": "ç†è§£å’Œç”Ÿæˆæ–‡æœ¬",
            "å±€é™": "è®¡ç®—èµ„æºè¦æ±‚é«˜",
            "ä¾‹å­": "ChatGPTã€æ–‡æœ¬ç”Ÿæˆ"
        }
    ]
    
    for i, stage in enumerate(stages, 1):
        print(f"\nç¬¬{i}é˜¶æ®µ: {stage['é˜¶æ®µ']}")
        print(f"  ğŸ’ª èƒ½åŠ›: {stage['èƒ½åŠ›']}")
        print(f"  âš ï¸  å±€é™: {stage['å±€é™']}")
        print(f"  ğŸ”§ ä¾‹å­: {stage['ä¾‹å­']}")
    
    print("\nğŸŒŸ æ„ŸçŸ¥æœºçš„æ°¸æ’ä»·å€¼:")
    print("  - æ˜¯ç†è§£AIçš„æœ€ä½³èµ·ç‚¹")
    print("  - ä»Šå¤©æ‰€æœ‰ç¥ç»ç½‘ç»œçš„åŸºç¡€å•å…ƒ") 
    print("  - ç®€å•ä½†è•´å«æ·±åˆ»åŸç†")
    print("  - è¿æ¥äº†ç”Ÿç‰©æ™ºèƒ½å’Œäººå·¥æ™ºèƒ½")

evolution_to_modern_ai()
```

## åŠ¨æ‰‹å®è·µï¼šè®©æ„ŸçŸ¥æœºè¯†åˆ«æ•°å­—

```python
def digit_recognition_demo():
    """ç”¨æ„ŸçŸ¥æœºè¯†åˆ«ç®€åŒ–çš„æ•°å­—"""
    
    # ç®€åŒ–çš„3x3åƒç´ æ•°å­—
    digits = {
        0: [
            [1, 1, 1],
            [1, 0, 1], 
            [1, 1, 1]
        ],
        1: [
            [0, 1, 0],
            [0, 1, 0],
            [0, 1, 0]
        ]
    }
    
    def display_digit(digit_matrix, label):
        """æ˜¾ç¤ºæ•°å­—"""
        print(f"\næ•°å­— {label}:")
        for row in digit_matrix:
            line = ""
            for pixel in row:
                line += "â–ˆ" if pixel else " "
            print(f"  {line}")
    
    # æ˜¾ç¤ºæ•°å­—
    for digit, matrix in digits.items():
        display_digit(matrix, digit)
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X_train = []
    y_train = []
    
    # åˆ›å»ºå¤šä¸ªå˜ç§æ¥å¢åŠ è®­ç»ƒæ•°æ®
    for digit, matrix in digits.items():
        # å°†3x3çŸ©é˜µå±•å¹³ä¸º9ç»´å‘é‡
        flattened = np.array(matrix).flatten()
        X_train.append(flattened)
        y_train.append(digit)
        
        # æ·»åŠ ä¸€äº›å™ªå£°ç‰ˆæœ¬
        for _ in range(3):
            noisy = flattened.copy()
            # éšæœºç¿»è½¬ä¸€ä¸ªåƒç´ 
            flip_idx = np.random.randint(0, 9)
            noisy[flip_idx] = 1 - noisy[flip_idx]
            X_train.append(noisy)
            y_train.append(digit)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    
    print(f"\nğŸ“ è®­ç»ƒæ•°æ®: {len(X_train)} ä¸ªæ ·æœ¬")
    
    # åˆ›å»ºæ„ŸçŸ¥æœºï¼ˆè¾“å…¥9ç»´ï¼Œè¾“å‡ºè¯†åˆ«æ˜¯å¦ä¸ºæ•°å­—1ï¼‰
    perceptron = SimplePerceptron(input_size=9)
    
    # å°†é—®é¢˜è½¬æ¢ä¸ºäºŒåˆ†ç±»ï¼šæ˜¯å¦ä¸ºæ•°å­—1
    binary_labels = (y_train == 1).astype(int)
    
    # è®­ç»ƒ
    print("\nå¼€å§‹è®­ç»ƒè¯†åˆ«æ•°å­—1...")
    for epoch in range(10):
        errors = 0
        for i in range(len(X_train)):
            if perceptron.train_step(X_train[i], binary_labels[i]):
                errors += 1
        
        if errors == 0:
            print(f"âœ… åœ¨ç¬¬ {epoch + 1} è½®è®­ç»ƒåå®Œå…¨å­¦ä¼šäº†ï¼")
            break
    
    # æµ‹è¯•
    print("\nğŸ§ª æµ‹è¯•è¯†åˆ«èƒ½åŠ›:")
    test_digit_0 = np.array(digits[0]).flatten()
    test_digit_1 = np.array(digits[1]).flatten()
    
    result_0 = perceptron.predict(test_digit_0)
    result_1 = perceptron.predict(test_digit_1)
    
    print(f"è¾“å…¥æ•°å­—0ï¼Œé¢„æµ‹ç»“æœ: {'æ˜¯æ•°å­—1' if result_0 else 'ä¸æ˜¯æ•°å­—1'} {'âœ…' if result_0 == 0 else 'âŒ'}")
    print(f"è¾“å…¥æ•°å­—1ï¼Œé¢„æµ‹ç»“æœ: {'æ˜¯æ•°å­—1' if result_1 else 'ä¸æ˜¯æ•°å­—1'} {'âœ…' if result_1 == 1 else 'âŒ'}")

digit_recognition_demo()
```

## æ€»ç»“ï¼šæ„ŸçŸ¥æœºçš„æ ¸å¿ƒæ€æƒ³

```python
def key_takeaways():
    """æ„ŸçŸ¥æœºçš„æ ¸å¿ƒè¦ç‚¹"""
    
    print("ğŸ¯ æ„ŸçŸ¥æœºçš„æ ¸å¿ƒæ€æƒ³")
    print("=" * 40)
    
    principles = [
        {
            "åŸç†": "æ¨¡ä»¿ç¥ç»å…ƒ",
            "è§£é‡Š": "åƒå¤§è„‘ç¥ç»å…ƒä¸€æ ·æ¥æ”¶å¤šä¸ªè¾“å…¥ï¼Œäº§ç”Ÿä¸€ä¸ªè¾“å‡º",
            "æ¯”å–»": "å°±åƒä¸€ä¸ªèªæ˜çš„é—¨å«ï¼Œæ ¹æ®å¤šä¸ªæ¡ä»¶å†³å®šæ˜¯å¦æ”¾è¡Œ"
        },
        {
            "åŸç†": "æƒé‡ä»£è¡¨é‡è¦æ€§", 
            "è§£é‡Š": "æ¯ä¸ªè¾“å…¥éƒ½æœ‰ä¸€ä¸ªæƒé‡ï¼Œæƒé‡è¶Šå¤§è¶Šé‡è¦",
            "æ¯”å–»": "å°±åƒæŠ•ç¥¨æ—¶ï¼Œä¸“å®¶çš„ç¥¨æ¯”æ™®é€šäººçš„ç¥¨æ›´æœ‰åˆ†é‡"
        },
        {
            "åŸç†": "å­¦ä¹ å°±æ˜¯è°ƒæ•´æƒé‡",
            "è§£é‡Š": "é€šè¿‡ä¸æ–­è¯•é”™ï¼Œè°ƒæ•´å„ä¸ªè¾“å…¥çš„é‡è¦æ€§",
            "æ¯”å–»": "å°±åƒå­¦å¼€è½¦ï¼Œä¸æ–­è°ƒæ•´å¯¹å„ç§è·¯å†µçš„ååº”"
        },
        {
            "åŸç†": "çº¿æ€§åˆ†ç±»å™¨",
            "è§£é‡Š": "åªèƒ½å¤„ç†çº¿æ€§å¯åˆ†çš„é—®é¢˜",
            "æ¯”å–»": "åªèƒ½ç”¨ä¸€æ¡ç›´çº¿æŠŠä¸¤ç±»ä¸œè¥¿åˆ†å¼€"
        }
    ]
    
    for i, principle in enumerate(principles, 1):
        print(f"\n{i}. {principle['åŸç†']}")
        print(f"   ğŸ“ è§£é‡Š: {principle['è§£é‡Š']}")
        print(f"   ğŸ­ æ¯”å–»: {principle['æ¯”å–»']}")
    
    print(f"\nğŸŒŸ ä¸ºä»€ä¹ˆæ„ŸçŸ¥æœºé‡è¦ï¼Ÿ")
    print("  - æ˜¯ç†è§£AIçš„ç¬¬ä¸€æ­¥")
    print("  - æ‰€æœ‰ç¥ç»ç½‘ç»œçš„åŸºç¡€")
    print("  - ç®€å•ä½†åŒ…å«æ ¸å¿ƒæ€æƒ³")
    print("  - è¿æ¥ç”Ÿç‰©å’Œäººå·¥æ™ºèƒ½")
    
    print(f"\nğŸš€ ä¸‹ä¸€æ­¥å­¦ä»€ä¹ˆï¼Ÿ")
    print("  - å¤šå±‚æ„ŸçŸ¥æœºï¼ˆè§£å†³XORé—®é¢˜ï¼‰")
    print("  - åå‘ä¼ æ’­ç®—æ³•")
    print("  - æ·±åº¦å­¦ä¹ åŸºç¡€")
    print("  - å·ç§¯ç¥ç»ç½‘ç»œ")

key_takeaways()
```

## ç»“è¯­

æ„ŸçŸ¥æœºè™½ç„¶ç®€å•ï¼Œä½†å®ƒæ˜¯äººå·¥æ™ºèƒ½å†å²ä¸Šçš„ä¸€ä¸ªé‡è¦é‡Œç¨‹ç¢‘ã€‚å®ƒæ•™ä¼šæˆ‘ä»¬ï¼š

1. **å¤æ‚æ™ºèƒ½å¯ä»¥ä»ç®€å•è§„åˆ™äº§ç”Ÿ** ğŸ§ 
2. **æœºå™¨å¯ä»¥é€šè¿‡ç»éªŒå­¦ä¹ ** ğŸ“š  
3. **æ•°å­¦å¯ä»¥æè¿°æ€ç»´è¿‡ç¨‹** ğŸ”¢
4. **ç”Ÿç‰©å¯å‘çš„ç®—æ³•å¨åŠ›å·¨å¤§** ğŸŒ±

ä»1957å¹´Rosenblattçš„ç¬¬ä¸€ä¸ªæ„ŸçŸ¥æœºï¼Œåˆ°ä»Šå¤©çš„ChatGPTï¼Œæ ¸å¿ƒæ€æƒ³ä¸€è„‰ç›¸æ‰¿ã€‚ç†è§£æ„ŸçŸ¥æœºï¼Œå°±æ˜¯ç†è§£AIçš„å¼€å§‹ï¼

ç°åœ¨ä½ å·²ç»æŒæ¡äº†æ„ŸçŸ¥æœºçš„æ ¸å¿ƒæ€æƒ³ï¼Œå‡†å¤‡å¥½æ¢ç´¢æ›´å¤æ‚çš„ç¥ç»ç½‘ç»œäº†å—ï¼ŸğŸš€

---

*æ¯ä¸ªä¼Ÿå¤§çš„AIç³»ç»Ÿï¼Œéƒ½æ˜¯ä»è¿™ä¸ªç®€å•çš„æ„ŸçŸ¥æœºå¼€å§‹çš„ï¼*
